{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "blodcells-conditional-gan-keras-implementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "source": [
        "# Bloodcells GAN\n",
        "https://www.kaggle.com/paultimothymooney/blood-cells?select=dataset2-master"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13xcva-Vr1iF"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKfOYiuKr1iG"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Concatenate\n",
        "from keras.layers import BatchNormalization, Activation, Embedding, multiply\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model, Sequential\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo8cLIZIr1iL"
      },
      "source": [
        "img_shape = (480, 640, 3)\n",
        "z_dim = 100\n",
        "num_classes = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDO5Hfd5r1iO"
      },
      "source": [
        "## The Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu50D75wr1iP"
      },
      "source": [
        "def build_generator(z_dim):\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(7*7*256, input_shape=(z_dim, )))\n",
        "    model.add(Reshape((7, 7, 256)))\n",
        "    \n",
        "    # 7*7*256 => 14*14*128\n",
        "    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    \n",
        "    # 14*14*128 => 14*14*64\n",
        "    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    \n",
        "    # 14*14*64 => 28*28*1\n",
        "    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(Activation('tanh'))\n",
        "    \n",
        "    z = Input(shape=(z_dim, ))\n",
        "    \n",
        "    # Conditioning label\n",
        "    label = Input(shape=(1,), dtype='int32')\n",
        "    \n",
        "    # embedding layer:\n",
        "    # turns labels into dense vectors of size z_dim\n",
        "    # produces 3D tensor with shape: (batch_size, 1, z_dim)\n",
        "    label_embedding = Embedding(num_classes, z_dim, input_length=1)(label)\n",
        "    \n",
        "    # Flatten the embedding 3D tensor into 2D  tensor with shape: (batch_size, z_dim)\n",
        "    label_embedding = Flatten()(label_embedding)\n",
        "    \n",
        "    # Element-wise product of the vectors z and the label embeddings\n",
        "    joined_representation = multiply([z, label_embedding])\n",
        "    \n",
        "    img = model(joined_representation)\n",
        "    \n",
        "    return Model([z, label], img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fziD5JnSr1iS"
      },
      "source": [
        "## The Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC-khGTDr1iT"
      },
      "source": [
        "def build_discriminator(img_shape):\n",
        "    \n",
        "    model = Sequential()\n",
        "    # 480*640*3 => 240*320*64 \n",
        "    # 28*28*2 => 14*14*64\n",
        "    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same', input_shape=(None,480, 640, 3)))\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    # 240*320*64 => 120*160*64\n",
        "    # 14*14*64 => 7*7*64\n",
        "    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    \n",
        "    # 7*7*128 => 3*3*128\n",
        "    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.01))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    img = Input(shape=img_shape)\n",
        "    \n",
        "    label = Input(shape=(1,), dtype='int32')\n",
        "    \n",
        "    # embedding layer:\n",
        "    # turns labels into dense vectors of size 28*28*1\n",
        "    # produces 3D tensor with shape: (batch_size, 1, 28*28*1)\n",
        "    label_embedding = Embedding(input_dim=num_classes, output_dim=np.prod(img_shape), input_length=1)(label)\n",
        "    # Flatten the embedding 3D tensor into 2D  tensor with shape: (batch_size, 28*28*1)\n",
        "    label_embedding = Flatten()(label_embedding)\n",
        "    # Reshape label embeddings to have same dimensions as input images\n",
        "    label_embedding = Reshape(img_shape)(label_embedding)\n",
        "    \n",
        "    # concatenate images with corresponding label embeddings\n",
        "    concatenated = Concatenate(axis=-1)([img, label_embedding])\n",
        "    \n",
        "    prediction = model(concatenated)\n",
        "    \n",
        "    return Model([img, label], prediction)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg3OjuwSr1iW"
      },
      "source": [
        "## Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMOPZ5Opr1iW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "outputId": "9fbf20a6-8b13-4b51-c4b9-fa2e2de08e37"
      },
      "source": [
        "# building and compiling the Discriminator\n",
        "disc = build_discriminator(img_shape)\n",
        "disc.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=Adam())\n",
        "\n",
        "# build the generator\n",
        "gen = build_generator(z_dim)\n",
        "\n",
        "# the generator takes noise and the target label as input\n",
        "# and generates the corresponding digit for that label\n",
        "z = Input(shape=(z_dim,))\n",
        "label = Input(shape=(1,))\n",
        "\n",
        "img = gen([z, label])\n",
        "\n",
        "# keep the discriminator's params constant for generator training\n",
        "disc.trainable = False\n",
        "\n",
        "prediction = disc([img, label])\n",
        "\n",
        "# Conditional (Conditional) GAN model with fixed discriminator to train the generator\n",
        "cgan = Model([z, label], prediction)\n",
        "cgan.compile(loss='binary_crossentropy', optimizer=Adam())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-99175d4d2c7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# building and compiling the Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdisc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# build the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-5a79ebf5a4a6>\u001b[0m in \u001b[0;36mbuild_discriminator\u001b[0;34m(img_shape)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mconcatenated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_embedding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcatenated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1090\u001b[0m       \u001b[0;31m# TODO(reedwm): We should assert input compatibility after the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m       \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Use `self._name_scope()` to avoid auto-incrementing the name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0;34m' incompatible with the layer: expected axis '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;34m' of input shape to have value '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 ' but received input with shape ' + str(shape))\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;31m# Check shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 3 but received input with shape [None, 480, 640, 6]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TlRVqvsr1ib"
      },
      "source": [
        "## Outputting sample images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E09wC0EWr1ib"
      },
      "source": [
        "def sample_images(image_grid_rows=2, image_grid_columns=5):\n",
        "    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n",
        "    labels = np.arange(0, 10).reshape(-1, 1)\n",
        "    gen_imgs = gen.predict([z, labels])\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "    fig, axs = plt.subplots(image_grid_rows, image_grid_columns, figsize=(10,4), sharey=True, sharex=True)\n",
        "    cnt = 0\n",
        "    for i in range(image_grid_rows):\n",
        "        for j in range(image_grid_columns):\n",
        "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "            axs[i,j].axis('off')\n",
        "            axs[i,j].set_title(\"Digit: %d\" % labels[cnt])\n",
        "            cnt += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAoz08por1ie"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD02uUXNyFyZ"
      },
      "source": [
        "#!unzip /content/blood.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eygHwcw5YSY"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder,filename))\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return images \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6HLJ82ur1if"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_data():\n",
        "  y_train = to_categorical(pd.read_csv('/content/labels.csv').to_numpy()[:, 2:])  \n",
        "  X_train = load_images_from_folder('/content/JPEGImages/')\n",
        " \n",
        "\n",
        "  return (X_train, y_train)#, (x_test, y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdGUrBdG6dIy"
      },
      "source": [
        "(X_train, y_train) = load_data()\n",
        "plt.imshow(X_train[10])\n",
        "print(y_train[10])\n",
        "#X_train[10].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXZgV9Ssr1ii"
      },
      "source": [
        "accuracies = []\n",
        "losses = []\n",
        "\n",
        "def train(iterations, batch_size, sample_interval):\n",
        "    \n",
        "    (X_train, y_train), (_, _) = load_data()\n",
        "    \n",
        "    X_train = (X_train - 127.5) / 127.5\n",
        "    X_train = np.expand_dims(X_train, axis=3)\n",
        "    \n",
        "    real = np.ones(shape=(batch_size, 1))\n",
        "    fake = np.zeros(shape=(batch_size, 1))\n",
        "    \n",
        "    for iteration in range(iterations):\n",
        "        \n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "        imgs, labels = X_train[idx], y_train[idx]\n",
        "        \n",
        "        z = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
        "        gen_imgs = gen.predict([z, labels])\n",
        "        \n",
        "        d_loss_real = disc.train_on_batch([imgs, labels], real)\n",
        "        d_loss_fake = disc.train_on_batch([gen_imgs, labels], fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "        \n",
        "        z = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
        "        labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "        \n",
        "        g_loss = cgan.train_on_batch([z, labels], real)\n",
        "        \n",
        "        if iteration % sample_interval == 0:\n",
        "            print('{} [D loss: {}, accuracy: {:.2f}] [G loss: {}]'.format(iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
        "        \n",
        "            losses.append((d_loss[0], g_loss))\n",
        "            accuracies.append(d_loss[1])\n",
        "            \n",
        "            sample_images()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9s5sm-0vXaT"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM9OIqper1il"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia721mbVr1il"
      },
      "source": [
        "iterations = 20000\n",
        "batch_size = 128\n",
        "sample_interval = 1000\n",
        "\n",
        "train(iterations, batch_size, sample_interval)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_7kGaJkr1ip"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}